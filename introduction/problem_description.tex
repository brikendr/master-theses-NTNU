\section{Problem Description}
This research study will try to answer two problems identified in the literature.

In Natural Language Processing (\ac{nlp}), supervised approaches that use machine learning or other artificial intelligence techniques perform best compared to semi-supervised and unsupervised approaches \cite{30}. Their performance highly depends on large amounts of annotated data (i.e. training data). This data is used by supervised approaches for either training the algorithm or evaluating the quality of annotations. The aforementioned training data is usually acquired by linguistic experts or trained annotators in a manual fashion. Consequently, the amount of training data required by a supervised algorithm to train its network is relatively big which makes the gathering process very time- and cost-intensive, yet important and necessary. As a result, the process of creating large-scale annotated training data has yet remained a long-standing barrier for many areas of \ac{nlp} \cite{41}.

Avoiding the idea of manually creating annotated corpus is not considered as a solution to the problem, since automatic approaches are still immature on performing such a complex task \cite{30}. Therefore, to be able to find the answer to the first problem, it is necessary to investigate different manual techniques that will make the process of creating annotated data sets less tedious and cost intensive. Since it is being dealt with the human factor, additional problems arise in terms of motivation, training and data quality assurance. This inevitably leads this research to address these human factor problems and attempts to investigate on potential techniques on how to train and motivate non-expert users to perform large-scale and high-quality annotations. This research study has been conducted as a motivation for finding an optimal solution to the problems stated above.