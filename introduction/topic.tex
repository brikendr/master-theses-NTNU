\section{Topic}
The incredible rapid advancements in information processing technologies and task automation using intelligent machine learning algorithms has opened up the discovery of novel "solutions" to high complexity problems for which machines were not able to solve before. However, despite these advancements, machine learning algorithms (also called supervised approaches) have been struggling on achieving high levels of quality and accuracy which in fields like natural language processing, speech recognition, semantic web and the like, is an inevitable and crucial requirement \cite{30}.

Natural Language Processing (\ac{nlp}) tasks generally fall into the category of artificial intelligence and machine learning problems and are considered to be relatively complex\cite{30, 12}. During the last decades, researchers have been focusing on solving problems ranging from language translation, word sense disambiguation, anaphora resolution and named entity disambiguation \cite{1,8,12,20,30}. This research study is particularly focused on the problem of named entity disambiguation. Tackling this problem results in improving, among others, searching accuracy on the WEB which contains a large proportion of unstructured documents that lack of meta-data (semantic meta-data) information crucial for improving performance\cite{semantic_search}. Named Entity Disambiguation, from now on referred to as \ac{ned}, is the process of linking a real world object (i.e. a named entity) appearing in textual data with a knowledge base. A Knowledge Base (\ac{kb}) is a machine-readable resource for the dissemination of information which is used to optimize information collection, organization and retrieval for an organization or the general public \cite{dbpedia}. Some of the most frequently used knowledge bases are Dbpedia, FOAF, Freebase, Geonames and many others generated during the past decade \cite{lod_sofar}. These knowledge bases are all part of the Linked Open Data Cloud initiative which aims at providing more complete answers to search engines as new data sources appear on the WEB \cite{lod_sofar}. An important and quite complex step for \ac{ned} is to disambiguate a named entity by finding a candidate (among many) from the knowledge base that best describes the entity, based on the context in which it occurs. The concept of bridging documents on the WEB with knowledge bases is helpful for linking the large amount of raw and noisy data present on the WEB which also contributes to Berners-Lee's proposed vision for the Semantic Web \cite{12}. However, identifying and correctly linking named entities with their corresponding counterparts on the knowledge base still remains a challenging task for machines because of the ambiguous nature of entities \cite{2}. 

To help assist and improve automatic algorithms in getting better at linking ambiguous entities, human input should be leveraged as a validation and quality assurance mechanism. In this context, assuring and maintaining high quality of annotations, users who take part in the validation process have to be either linguistic experts or trained annotators. However, very little research has been done towards supporting non-expert users in the process of creating semantically-enriched content, i.e. annotating unstructured documents \cite{15}. A not so popular approach to collaborative resource creation which is investigated in this research study, is intrinsically motivating users to create annotations by using a so-called Game With A Purpose (\ac{gwap}) which produces annotations as a byproduct of users playing the game \cite{vonahn}. Providing that the game is entertaining enough to attract sufficient players, according to Poesio et al. \cite{44}, it should be possible to carry out large-scale annotations of documents at smaller cost compared to other approaches such as crowdsourcing. This research study is primarily focused on investigating whether a gamified system that is based on theoretical models and build on top of a complete \ac{ned} framework can provide qualitative and accurate annotations by non-expert annotators compared to annotations performed by linguistic experts. Furthermore, we investigate on game design elements and techniques to intrinsically motivate users to do annotations without using any form of payment incentives, thus keeping cost at the lowest level possible. Finally, the generated annotations by the non-expert users (players) shall be used by artificial intelligence or machine learning algorithms as training data and also by other tools that aim at enriching unstructured web documents with semantic content.