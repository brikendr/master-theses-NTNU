\section{Research Questions \& Hypothesis}
Automatic named entity disambiguation has been extensively researched by previous studies, therefore, the focus of this research study is not directly improving the task itself. Instead, we focus on providing means that will help future researchers easily gather up-to-date training data for improving the accuracy of \ac{ned} systems. With that being said, our main focus is finding a suitable approach for leveraging human input as a validation mechanisms for generating trustful and qualitative training data for supervised algorithms. The following research questions and hypothesis will help us conclude whether using gamification and non-expert annotators is a suitable approach for improving some of the supervised and semi-supervised algorithms in natural language processing:  
\begin{itemize}
    \item How accurate can an entity disambiguation framework, by using human input, validate the automatic linking process of named entities with knowledge bases?
    \item  What features can be used to formulate the surrounding context of entities so that non-expert users can correctly disambiguate them? 
    \item What game mechanics can be employed in the entity disambiguation task so that high levels of engagement are achieved while still maintaining annotation quality?
\end{itemize}

%\begin{itemize}\item \textbf{Why is it important? }Finding the answer to this RQ can help us use the framework for recognizing entities, extracting context clues and generating KB candidates for different types of tasks such as the task of entity resolution, WSD in different areas of expertise like: Education, Medicine, Science, Geography etc.
%\item \textbf{What have other people done?} In terms of implementing a generic frameowork. there are not many studies where they have utilized the whole pipeline into one standalone system. Most of previous studies have focused on automatic generation and validation, without including human input (For example the OKE Challenge).
%\item \textbf{What have they found?} Previous research has found that among the three different entity resolution techniques (Unsupervised, Semi-Supervised and Supervised Approaches), the supervised approaches have always outperformed the other two. This means that, in order to provide a trustful system for EntityLinking or WSD, supervised approaches should achieve at least a 90\% accuracy. This is only possible by training the supervised approaches with many data.
%\item \textbf{Hypothesis}: \textit{By implementing the complete entity resolution pipeline as a framework, non-expert users will be able to perform annotation with a quality compared to expert annotators!}
%\item \textbf{AIMS}: Implement the complete entity resolution pipeline as a microservice architecture framework where the microservices such as NER, Context Clue Extraction, Candidate Generation and Annotation Preparation; all utilize the advantages of the microservice architecture being loosely coupeled and allowing the flexibility of manipulating with different techniques without blocking work flow.\end{itemize}
    
%\begin{itemize}\item \textbf{Why is this important} Properly formulating the context around the target entity is of great importance because when annotating users tend to favor tasks that do not require them to read a lot of text to make a decision. Having accurate and short contextual clues avoids the boring task of having to read a lot of text while making the task interesting and more quiz like. It is important for the next step (the game) to have short context clues rather than long sentences as this may degrade the engagement end overall enjoyability of the gameplay.
%\item \textbf{What have other people done?} There is a lot of literature in terms of defining context and the various techniques of extracting contextual clues. Regarding specifically the problem of entity resolution or WSD, previous research has focused on extracting context clues that can help automatic semi-supervised or supervised approaches for using context as a piece of information that helps the algorithm make an informed decision on which candidate best represents the targeting entity. No previous research study is focused on formulating the context which is helpful for human annotators to disambiguate an entity
%\item \textbf{What have they found} ??
%\item H2.1: \textit{Short contextual clues are preferred towards complete sentences or paragraphs and they provide sufficient information to make correct annotation decisions!}
%\item \textbf{AIMS}: Implement a generic algorithm that will extract contextual clues around a target entity by using different NLP techniques!\end{itemize}

%\begin{itemize}\item \textbf{Why is this important?} Entity resolution and linking is a very tedious and boring task for human annotators to perform. Having a way at which the human annotators would enjoy the process of performing annotations without being bored or feeling used as workers would really benefit the research community for generating large amount of training data which then can be used to train supervised approaches and improve the state of the art in entity resolution and WSD. Since Games With A Purpse have been in the focus of researchers during the recent years, intrinsically motivating users can only be achieved by implementing a game that fullfils the needs of competance, autonomy and relatedness to the players. This potentially results retaining users because they are being intrinsically motivated to play the game and not extrinsically motivated (for example by paying incentives which could potentially result in degrading the quaity of annotations)
%solution as well. Recent research suggests that majority of previous studies where they have utilized GWAPS for performng anntoations do not base their implementations in theoritical models such as SDT and thus fail to convince the research community that their users were intrinsically motivated to perform the task.
%\item \textbf{H3.1} - \textit{By employing game mechanics that are based on theoritical models of STD, players will be intrinsically motivated to play the game compared to using a plain interface for annotation}
%\item \textbf{H3.2} - \textbf{By supporing H3.1, we can further hypothesize that users who have used the plain interface and the game to performa annotations will choose the game significantly more than the interface}
%\item \textbf{AIMS} - Implement a game that consists of various game mechanics which are based on the self determination theory and will positively affect the feelings of competance, autonomy and relatedness and thus intrinsically motivating them to play the game. Two experiments shall e conducted, one with a plain interface and the other using the game to compare the performanceas as well as the users perception towards enjoyabiltity, engagement, competance, autonomy and social factor of both annotation interfaces
%\end{itemize}