% - Defining Context 
\section{Defining Context}
\label{background:defininf_context}
Extracting information about the surrounding context of a word, an entity or even the context of the document as a whole (topic context) is one of the most important and yet most difficult tasks to achieve in \ac{nlp}. The surface form "Texas", according to Wikipedia, can refer to no more than twenty different named entities that can potentially describe the surface form based on the context it occurs. It may refer to the University of Texas, a Texas British Pop-Band, the US State of Texas or a novel named "Texas" written by Jams Michner \cite{24}. 

Context has the power of being virtually anything, and it can be seen as a container in which the phenomenon resides \cite{25}. It represents the parts of a discourse that surround a word or passage and can clarify the meaning or the interrelated conditions in which something exists or occurs \cite{22}. Bontas and Paslaru \cite{22} argue that contexts does not represent actual situations but it represents the perspective of an agent of the situation, since context is considered to be a partial approximation of a complete state of the world given a time point \cite{22,25}. Many studies see contextual information as a path that leads supervised algorithm or human annotator to make a clear decision on the disambiguation process of ambiguous surface forms (words). 

Furthermore, besides eliminating ambiguities, context may be used for completing the missing information in natural language utterances \cite{22}. The level of impact that context has in the performance of \ac{nlp} tasks, has taken the attention of many researchers who have been trying to formulate or define the context for many years \cite{35,37,28,29,26,38}. However, context processing largely depends on the application domain, and the procedures used to formulate it are way too specific to be used in a generic scope. Therefore, Bontas and Paslaru \cite{22} state that no clear and common methodology exists (yet) for the development of context-aware applications irrespective of the domain they belong to.   

Some of the most common used features for disambiguating the sense of an ambiguous word and also defining the surrounding context of a word include: surround words and their Part-Of-Speech (POS) tags, topic keywords, content bigrams and various syntactic properties \cite{36}. Topic keywords are considered as topical features that represent the general context of a document in which the ambiguous word resides. Unlike local features, topical features define the general topic of the document and represent a more generic context \cite{30}. On the other hand, local feature such as bi-grams and surround words are important to pin down more specific contextual information. Bigrams are ordered pairs of words that are judged statistically significant by a measure of association. They often provide very specific unambiguous clues regarding the content of a context \cite{26}. Navigli \cite{30} states that deciding on the appropriate size of context (the number of bigrams, surround words, topic keywords etc) is an important factor in the development of \ac{nlp} tasks such as \ac{ned} and \ac{wsd}. Inappropriate formulation of the context size is known to negatively affect the disambiguation performance of these tasks \cite{30}. 

