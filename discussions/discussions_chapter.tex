\chapter{Discussions}
\label{chap:discussions}

Named entity linking and disambiguation has been a problem for which many studies have tried to find an effective solution either by using automatic supervised algorithms or utilizing human input for validation and generation of annotation data \cite{39, 9, dbpedia, 16, 31}. Despite the advancement of supervised techniques using machine learning algorithms, tasks such as \ac{ned} and \ac{wsd} still haven not reached a satisfactory performance for generating trustful data quality \cite{30}. Relying on human input for validating these automatic approaches has been seen as the only way for progressing in this aspect. A question which has drawn constant attention is whether non-expert human annotators are capable of generating annotations with a quality comparable to expert annotations. The implementation of a complete \ac{ned} framework which was used to generate annotations using non-expert annotators in an experimental setup reveal that these users are capable of generating annotations with an accuracy of 0.92 (F-score).


\section{A framework that supports qualitative annotations}
These findings are complementary with previous work which also tested the ability of non-expert users to perform tasks for \ac{ned} and \ac{wsd} \cite{14,16,9,32}. However, previous human centered approaches for \ac{ned} were either focused on assessing the usability of their interfaces \cite{15,16,17} or they used human annotators for temporarily validating automatic generated data without utilizing such power in the future \cite{31,32,33}. On the other hand, automatic supervised and unsupervised techniques for \ac{ned} have implemented complete systems with some of them performing relatively well \cite{39, 21}. With the implementation of a loosely coupled microservice architectural framework that utilizes the best systems and techniques from the automatic approaches and usability best practices from human centered studies, this research study refines previous work by effectively combining these two approaches to get the most out of automation and using human input only in essential parts such as validating and disambiguation. Analysis and findings from the results acquired during experimental trials throughout this research project show that it is possible to rely on non-expert human annotators for generating qualitative data using the implemented framework. The generated data can be used to enrich HTML content with semantic data from \ac{lod} knowledge bases or train supervised approaches until they are mature enough to disregard human judgments.  

\section{Short clues as context representatives}
Among the reviewed human centered research studies, whether they used crowdsourcing or gamification for utilizing human validation, none of them had attempted to properly define or formalize contextual information in texts document in an automated way to assist human annotators on the disambiguation process. Supervised automatic algorithms on the other hand have formalized contextual information as features to feed in into the algorithms showed improvements on disambiguation performance \cite{24,29,33}. However, these contextual features are designed for intelligent algorithms and are not as helpful for human annotators. Therefore, this study extends on previous work by providing a service that can effectively generate contextual information surrounding the target entities which might help non-expert annotators easily disambiguate ambiguous entities. Our findings reveal that participants tend to prefer short contextual clues instead of complete sentences. However, because of limitations in the methodology chosen to assess the effectiveness of these clues, it was not possible to make such a claim that the clues generated by our service provide sufficient information for annotators to correctly disambiguate an entity. The main reason that resulted in choosing a rather poor and inappropriate evaluation methodology for assessing the effectiveness of contextual clues is the lack of time resources in conducting a third experiment. Therefore, we acknowledge the fact that asking the participants in the post-questionnaire whether the context clues were useful without actually testing this variable in a two-fold experimental setup was not the best methodology employed and it is considered a limitation to our study. 

However, when designing the game, this problem was solved by using another approach of feeding context to the user. In addition to the short contextual clues, users were additionally exposed with the complete sentence but in a way which does not overwhelm them and avoids redundant cognitive load. The design of the game task made it possible to use the sentence for communicating the context unconsciously by having the user type the complete sentence as part of a fun activity (fast typing). This proved to be significantly effective since the quality of annotation remained the same during the second experiment.

\if However, since the results show high levels of annotation quality and moderate agreement levels between participants, we assume that the contextual clues generated by our framework are significantly more user-friendly and exhibit significantly less cognitive load to the participant compared to showing complete sentences. At the end of the day, our goal was to keep users motivated and interested to contribute in generating annotations. Therefore, using long sentences as contextual clues would potentially result in negatively affecting the UI/UX of the interface and the player's motivation to play. \fi

\section{Gamifying non-gaming systems}
Since the results from the first experiment revealed that the micro-service architectural framework for \ac{ned} supports the generation of qualitative annotation by non-expert users, we have used this framework as a foundation on top of which a gamified system was build in order to intrinsically motivate users for contributing instead of using payment incentives like crowdsourcing \cite{9,32,33}. In general, our findings corroborate with previous work in gamification that game mechanics and game design principles can be applied in non-gaming context in order to make the task more engaging and fun to interact \cite{44,45,50}. Some research studies in gamification of annotation tasks for \ac{wsd} show that gamification helped in improving annotation quantity with no significant results in the improvement of annotation quality \cite{46}. Our results extend on these previous work that gamification can be used for not only increasing annotation quantity but also maintain high levels of quality. By observing and analyzing the results of our study, we continute to support the idea that applying game elements in non-gaming context does not necessarily motivate users and improve quality and quantity of annotations unless psychological needs for intrinsic motivation are satisfied.

\section{Limitations}
Results from the second experiment reveal that the game mechanics and the overall design of the game positively affected users needs satisfaction and intrinsic motivation to contribute. However, it is important to address that there might be some potential bias in assessing the users initial motivation to participate in the study. In our experiment, we recruited participants that were mainly bachelor or master degree students studying at the university campus. It is known from previous research studies that participants from the university usually engage voluntarily in studies and it is possible that they already had a minimum level of intrinsic motivation from the get-go effect, which might have affected the results. Additionally, the population used in the experiment consisted of students with higher education in the field of computer science, information security and interaction design. Thus, one might argue that the label "non-expert annotators" cannot be applied to this type of population. However, the game was designed in a way that every player, regardless of their educational background, had to go through the onboarding process which is a gamified version of a training stage and assures that players understand the game elements by slowly exploring the complexity of the game. Besides the fact that we were limited in the type of population that was available to conduct the study with, we stay behind our claims that the framework and the game design supports the generation of qualitative annotations by non-expert users. Despite the acquired significant results and our confidence in generating qualitative annotations with the population at hand, more research is required to investigate how users' initial motivation to engage in gamified application affects their subsequent motivation and also test the game with users that better represent the general target population\cite{46}.

\section{Practical and theoretical implications}
The main lesson learned from applying the gamification process to the named entity disambiguation framework is that game design can be applied to any non-gaming contexts as long as the design conforms to empirical and psychological foundations with all game elements directly or indirectly contributing to the solution of the problem at hand. The real challenge in designing a game with a purpose is finding a model that is appropriate for the task but also contributes to user engagement and intrinsic motivation. Controlling players for malicious behaviour, maintaining players within the defined flow-zone of game complexity, providing meaningful content, non-formal feedback that is visually and aurally attractive without shifting the players concentration and focus from the main task are aspects which when appropriately addressed, contribute a great deal towards having an enjoyable \ac{gwap}. In Fastype, all the game elements contribute to the general idea of providing qualitative annotations and each game element plays an important role in helping players make correct disambiguation decisions. Designing a game that encourages competitive players to unleash their competitive nature into the gameplay while also providing a safe game environment for players that prefer to play safe without taking risks are additional game design factors that characterize a well-thought \ac{gwap}. Though, some research studies which have investigated on gamifing WSD and entity linking argue that text-based games are limited in their potential compared to 2d video-games, our results conflict with these claims \cite{54}. This research work, based on statistically significant results, rejects the claims stated by Vannella et al. \cite{52} by proving that even text-based \ac{gwap} can be as engaging and entertaining as 2D video-games when it comes to truly engaging a player.